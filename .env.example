# LLM Provider Selection
# Options: local, openai, gemini
LLM_PROVIDER=local

# Local LLM Path (Optional override)
# LOCAL_MODEL_PATH=models/llama3.1/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf

# External API Keys (Required if provider is openai or gemini)
OPENAI_API_KEY=sk-your-openai-key-here
GEMINI_API_KEY=AIza-your-gemini-key-here

# External Model Selection (Optional)
# OPENAI_MODEL=gpt-4-turbo-preview
# GEMINI_MODEL=gemini-pro
